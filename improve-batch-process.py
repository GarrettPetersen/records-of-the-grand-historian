#!/usr/bin/env python3
"""
Improved Batch Translation Process

This script demonstrates a better workflow:
1. Extract smaller batches (15-20 sentences)
2. Pre-read all content before translating
3. Translate with immediate quality checks
"""

import json
import sys
from pathlib import Path

def improved_batch_workflow(chapter_file, batch_size=15):
    """
    Improved workflow with smaller batches and pre-reading
    """
    print(f"ğŸ¯ Starting improved translation workflow for {chapter_file}")
    print(f"ğŸ“ Batch size: {batch_size} sentences")
    print(f"ğŸ“– Pre-reading phase...")

    # Load and analyze the chapter
    with open(chapter_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    total_sentences = data['meta']['sentenceCount']
    print(f"ğŸ“Š Chapter has {total_sentences} sentences")

    # Calculate optimal batching
    full_batches = total_sentences // batch_size
    remainder = total_sentences % batch_size

    print(f"ğŸ”¢ Will create {full_batches} full batches + {remainder} in final batch")

    # Pre-read all content (this would be done by the translation script)
    print("
âœ… Pre-read complete - ready for translation"    print("ğŸ’¡ Benefits of this approach:"    print("  â€¢ Complete context before starting")
    print("  â€¢ Smaller, manageable batches")
    print("  â€¢ Better quality control")
    print("  â€¢ Reduced cognitive load per session")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python improve-batch-process.py <chapter_file> [batch_size]")
        sys.exit(1)

    chapter_file = sys.argv[1]
    batch_size = int(sys.argv[2]) if len(sys.argv) > 2 else 15

    improved_batch_workflow(chapter_file, batch_size)
